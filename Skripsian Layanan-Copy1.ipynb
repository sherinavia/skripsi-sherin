{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/KULIAH/SEMESTER 7/skripsi bismillah fix/SHERINA AVIANITA/svm/layanan/aspek_layanan2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wong tengah</td>\n",
       "      <td>Ribet pemesanannya</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saiful Rijal</td>\n",
       "      <td>tidak masuk pelayanannya</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fitri Ayu Meriana</td>\n",
       "      <td>pelayanan cepat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toni Dimas A.</td>\n",
       "      <td>lama pelayanan beli nasi sayur akhirnya aku ti...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alex Budiman</td>\n",
       "      <td>Pelayanan Cepat &amp; Kasir untuk Ojek Online dise...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Erasmus Reyhan I</td>\n",
       "      <td>Untuk parkiran baik motor atau mobil cukup lua...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Saka Tara</td>\n",
       "      <td>Enak buat nongkrong, selalu konsisten pelayana...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pyu chan</td>\n",
       "      <td>Nongkrong sekaligus kuliner. Pesan dulu makana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>suharmono simon</td>\n",
       "      <td>Kurang memuaskan pelayanan dan makanannya</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Eko Rahmad Hermansah</td>\n",
       "      <td>pelayanan baik</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Reviewer Name                                             Review  \\\n",
       "0           wong tengah                                 Ribet pemesanannya   \n",
       "1          Saiful Rijal                           tidak masuk pelayanannya   \n",
       "2     Fitri Ayu Meriana                                    pelayanan cepat   \n",
       "3         Toni Dimas A.  lama pelayanan beli nasi sayur akhirnya aku ti...   \n",
       "4          Alex Budiman  Pelayanan Cepat & Kasir untuk Ojek Online dise...   \n",
       "5      Erasmus Reyhan I  Untuk parkiran baik motor atau mobil cukup lua...   \n",
       "6             Saka Tara  Enak buat nongkrong, selalu konsisten pelayana...   \n",
       "7              pyu chan  Nongkrong sekaligus kuliner. Pesan dulu makana...   \n",
       "8       suharmono simon          Kurang memuaskan pelayanan dan makanannya   \n",
       "9  Eko Rahmad Hermansah                                     pelayanan baik   \n",
       "\n",
       "   Label  \n",
       "0     -1  \n",
       "1     -1  \n",
       "2      1  \n",
       "3     -1  \n",
       "4      1  \n",
       "5      1  \n",
       "6      1  \n",
       "7      0  \n",
       "8     -1  \n",
       "9      1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df['No']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case folding \n",
    "\n",
    "def caseFolding(textReview):\n",
    "\n",
    " textReview = textReview.lower()\n",
    " return(textReview)\n",
    "\n",
    "# apply to each datas and insert them into new column\n",
    "df['case folding'] = df['Review'].apply(lambda x:\n",
    "caseFolding(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Punctuation\n",
    "\n",
    "def cleansing(textReview):\n",
    " # remove numbering\n",
    " textReview = [re.sub('[0-9]', '', i) for i in textReview]\n",
    " # remove punct\n",
    " textReview = \"\".join([c for c in textReview if c not in\n",
    "string.punctuation])\n",
    " # remove enter\n",
    " textReview = textReview.replace('\\n',' ')\n",
    " return textReview\n",
    "\n",
    "# apply to each datas and insert them into new column\n",
    "df['cleansing'] = df['case folding'].apply(lambda x: cleansing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# To detect a word character (a-z, A-Z, 0-9, _)\n",
    "wordTokenize = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Function to detect empty string\n",
    "def removeEmptyToken(textReview):\n",
    " textReview = [x for x in textReview if len(x) > 0]\n",
    " return textReview\n",
    "\n",
    "# apply to each datas and insert them into new column\n",
    "df['tokenizing'] = df['cleansing'].apply(lambda x:\n",
    "wordTokenize.tokenize(x))\n",
    "df['tokenizing'] = df['tokenizing'].apply(lambda x:\n",
    "removeEmptyToken(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopword Removal\n",
    "\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover,ArrayDictionary \n",
    "\n",
    "# stopword removal\n",
    "factory_stopword = StopWordRemoverFactory().get_stop_words()\n",
    "exclude_from_stopword= ['tidak', 'namun', 'sementara', 'hanya', 'sedangkan', 'tetapi', 'kecuali', 'agak']\n",
    "remove_word = ([word for word in factory_stopword if word not in exclude_from_stopword])\n",
    "add_word=['sih','loh','kok','aja','deh','lah','nah', 'yg', 'kalau', 'lalu', 'nya', 'sini', 'sangat', 'banget']\n",
    "data= remove_word + add_word\n",
    "final_dictionary= ArrayDictionary(data)\n",
    "\n",
    "def stopwords(textReview):\n",
    "    stopword_remover = StopWordRemover(final_dictionary)\n",
    "    textReview = [stopword_remover.remove(x)for x in textReview]\n",
    "    return(textReview)\n",
    "\n",
    "df['stopwords'] = df['tokenizing'].apply(lambda x:stopwords(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "from Sastrawi.Dictionary.ArrayDictionary import ArrayDictionary\n",
    "from Sastrawi.StopWordRemover.StopWordRemover import StopWordRemover\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# Stemming function to change all affixed words into basic tenses\n",
    "def word_stemmer(textReview):\n",
    "    factorystemmer = StemmerFactory()\n",
    "    stemmer = factorystemmer.create_stemmer()\n",
    "    textReview = [stemmer.stem(x)for x in textReview]\n",
    "    return(textReview)\n",
    "\n",
    "# apply to each datas and insert them into new column\n",
    "df['stemming'] = df['stopwords'].apply(lambda x:word_stemmer(x))\n",
    "\n",
    "# Function to detect empty token\n",
    "def removeEmptyToken(textReview):\n",
    "    textReview = [x for x in textReview if len(x) > 0]\n",
    "    return textReview\n",
    "\n",
    "# apply to each datas and insert them into new column\n",
    "df['final preprocessing'] = df['stemming'].apply(lambda x:\n",
    "removeEmptyToken(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Menyimpan Hasil Preprocessing\n",
    "\n",
    "df.to_csv('C:/KULIAH/SEMESTER 7/skripsi bismillah fix/SHERINA AVIANITA/svm/layanan/skripsi/preprocessing_test_copy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "      <th>case folding</th>\n",
       "      <th>cleansing</th>\n",
       "      <th>tokenizing</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>stemming</th>\n",
       "      <th>final preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wong tengah</td>\n",
       "      <td>Ribet pemesanannya</td>\n",
       "      <td>-1</td>\n",
       "      <td>ribet pemesanannya</td>\n",
       "      <td>ribet pemesanannya</td>\n",
       "      <td>['ribet', 'pemesanannya']</td>\n",
       "      <td>['ribet', 'pemesanannya']</td>\n",
       "      <td>['ribet', 'mesan']</td>\n",
       "      <td>['ribet', 'mesan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saiful Rijal</td>\n",
       "      <td>tidak masuk pelayanannya</td>\n",
       "      <td>-1</td>\n",
       "      <td>tidak masuk pelayanannya</td>\n",
       "      <td>tidak masuk pelayanannya</td>\n",
       "      <td>['tidak', 'masuk', 'pelayanannya']</td>\n",
       "      <td>['tidak', 'masuk', 'pelayanannya']</td>\n",
       "      <td>['tidak', 'masuk', 'layan']</td>\n",
       "      <td>['tidak', 'masuk', 'layan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fitri Ayu Meriana</td>\n",
       "      <td>pelayanan cepat</td>\n",
       "      <td>1</td>\n",
       "      <td>pelayanan cepat</td>\n",
       "      <td>pelayanan cepat</td>\n",
       "      <td>['pelayanan', 'cepat']</td>\n",
       "      <td>['pelayanan', 'cepat']</td>\n",
       "      <td>['layan', 'cepat']</td>\n",
       "      <td>['layan', 'cepat']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toni Dimas A.</td>\n",
       "      <td>lama pelayanan beli nasi sayur akhirnya aku ti...</td>\n",
       "      <td>-1</td>\n",
       "      <td>lama pelayanan beli nasi sayur akhirnya aku ti...</td>\n",
       "      <td>lama pelayanan beli nasi sayur akhirnya aku ti...</td>\n",
       "      <td>['lama', 'pelayanan', 'beli', 'nasi', 'sayur',...</td>\n",
       "      <td>['lama', 'pelayanan', 'beli', 'nasi', 'sayur',...</td>\n",
       "      <td>['lama', 'layan', 'beli', 'nasi', 'sayur', 'ak...</td>\n",
       "      <td>['lama', 'layan', 'beli', 'nasi', 'sayur', 'ak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alex Budiman</td>\n",
       "      <td>Pelayanan Cepat &amp; Kasir untuk Ojek Online dise...</td>\n",
       "      <td>1</td>\n",
       "      <td>pelayanan cepat &amp; kasir untuk ojek online dise...</td>\n",
       "      <td>pelayanan cepat  kasir untuk ojek online disen...</td>\n",
       "      <td>['pelayanan', 'cepat', 'kasir', 'untuk', 'ojek...</td>\n",
       "      <td>['pelayanan', 'cepat', 'kasir', '', 'ojek', 'o...</td>\n",
       "      <td>['layan', 'cepat', 'kasir', '', 'ojek', 'onlin...</td>\n",
       "      <td>['layan', 'cepat', 'kasir', 'ojek', 'online', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reviewer Name                                             Review  \\\n",
       "0        wong tengah                                 Ribet pemesanannya   \n",
       "1       Saiful Rijal                           tidak masuk pelayanannya   \n",
       "2  Fitri Ayu Meriana                                    pelayanan cepat   \n",
       "3      Toni Dimas A.  lama pelayanan beli nasi sayur akhirnya aku ti...   \n",
       "4       Alex Budiman  Pelayanan Cepat & Kasir untuk Ojek Online dise...   \n",
       "\n",
       "   Label                                       case folding  \\\n",
       "0     -1                                 ribet pemesanannya   \n",
       "1     -1                           tidak masuk pelayanannya   \n",
       "2      1                                    pelayanan cepat   \n",
       "3     -1  lama pelayanan beli nasi sayur akhirnya aku ti...   \n",
       "4      1  pelayanan cepat & kasir untuk ojek online dise...   \n",
       "\n",
       "                                           cleansing  \\\n",
       "0                                 ribet pemesanannya   \n",
       "1                           tidak masuk pelayanannya   \n",
       "2                                    pelayanan cepat   \n",
       "3  lama pelayanan beli nasi sayur akhirnya aku ti...   \n",
       "4  pelayanan cepat  kasir untuk ojek online disen...   \n",
       "\n",
       "                                          tokenizing  \\\n",
       "0                          ['ribet', 'pemesanannya']   \n",
       "1                 ['tidak', 'masuk', 'pelayanannya']   \n",
       "2                             ['pelayanan', 'cepat']   \n",
       "3  ['lama', 'pelayanan', 'beli', 'nasi', 'sayur',...   \n",
       "4  ['pelayanan', 'cepat', 'kasir', 'untuk', 'ojek...   \n",
       "\n",
       "                                           stopwords  \\\n",
       "0                          ['ribet', 'pemesanannya']   \n",
       "1                 ['tidak', 'masuk', 'pelayanannya']   \n",
       "2                             ['pelayanan', 'cepat']   \n",
       "3  ['lama', 'pelayanan', 'beli', 'nasi', 'sayur',...   \n",
       "4  ['pelayanan', 'cepat', 'kasir', '', 'ojek', 'o...   \n",
       "\n",
       "                                            stemming  \\\n",
       "0                                 ['ribet', 'mesan']   \n",
       "1                        ['tidak', 'masuk', 'layan']   \n",
       "2                                 ['layan', 'cepat']   \n",
       "3  ['lama', 'layan', 'beli', 'nasi', 'sayur', 'ak...   \n",
       "4  ['layan', 'cepat', 'kasir', '', 'ojek', 'onlin...   \n",
       "\n",
       "                                 final preprocessing  \n",
       "0                                 ['ribet', 'mesan']  \n",
       "1                        ['tidak', 'masuk', 'layan']  \n",
       "2                                 ['layan', 'cepat']  \n",
       "3  ['lama', 'layan', 'beli', 'nasi', 'sayur', 'ak...  \n",
       "4  ['layan', 'cepat', 'kasir', 'ojek', 'online', ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('C:/KULIAH/SEMESTER 7/skripsi bismillah fix/SHERINA AVIANITA/svm/layanan/skripsi/preprocessing_test_copy.csv', index_col=0)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abis</th>\n",
       "      <th>ac</th>\n",
       "      <th>acung</th>\n",
       "      <th>ada</th>\n",
       "      <th>adain</th>\n",
       "      <th>aduh</th>\n",
       "      <th>again</th>\n",
       "      <th>agak</th>\n",
       "      <th>agam</th>\n",
       "      <th>agin</th>\n",
       "      <th>...</th>\n",
       "      <th>waktu</th>\n",
       "      <th>wanita</th>\n",
       "      <th>waras</th>\n",
       "      <th>wib</th>\n",
       "      <th>wifi</th>\n",
       "      <th>wkwk</th>\n",
       "      <th>worth</th>\n",
       "      <th>yaa</th>\n",
       "      <th>yups</th>\n",
       "      <th>yupskuliner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 755 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abis   ac  acung  ada  adain  aduh  again  agak  agam  agin  ...  waktu  \\\n",
       "0   0.0  0.0    0.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0  ...    0.0   \n",
       "1   0.0  0.0    0.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0  ...    0.0   \n",
       "2   0.0  0.0    0.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0  ...    0.0   \n",
       "3   0.0  0.0    0.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0  ...    0.0   \n",
       "4   0.0  0.0    0.0  0.0    0.0   0.0    0.0   0.0   0.0   0.0  ...    0.0   \n",
       "\n",
       "   wanita  waras  wib  wifi  wkwk  worth  yaa  yups  yupskuliner  \n",
       "0     0.0    0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  \n",
       "1     0.0    0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  \n",
       "2     0.0    0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  \n",
       "3     0.0    0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  \n",
       "4     0.0    0.0  0.0   0.0   0.0    0.0  0.0   0.0          0.0  \n",
       "\n",
       "[5 rows x 755 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Term Weighting TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_weighting = TfidfVectorizer()\n",
    "\n",
    "# Implement the fit transformation of TF-IDF calculation (matrix)\n",
    "tfidf_fit_transform = tfidf_weighting.fit_transform(df2['final preprocessing'])\n",
    "                                                           \n",
    "# Extract data from dataset features (terms) to column\n",
    "tfidf_feature_names = tfidf_weighting.get_feature_names()\n",
    "\n",
    "# Return a dense matrix representation of a matrix NDFrame\n",
    "tfidf_dense = tfidf_fit_transform.todense()\n",
    "\n",
    "# Convert a series into list\n",
    "tfidf_denselist = tfidf_dense.tolist()\n",
    "\n",
    "# Save the result of weighting to a DataFrame\n",
    "df_tfidf_final = pd.DataFrame(tfidf_denselist, columns=tfidf_feature_names)\n",
    "\n",
    "# Export the results (DataFrame) to Excel file\n",
    "df_tfidf_final.to_csv('C:/KULIAH/SEMESTER 7/skripsi bismillah fix/SHERINA AVIANITA/svm/layanan/skripsi/tfidf_test_copy.csv', encoding='utf-8')\n",
    "\n",
    "df3 = pd.read_csv('C:/KULIAH/SEMESTER 7/skripsi bismillah fix/SHERINA AVIANITA/svm/layanan/skripsi/tfidf_test_copy.csv', index_col=0)\n",
    "df3.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikasi SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sherin\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\sherin\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\sherin\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\sherin\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\sherin\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\sherin\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\sherin\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\sherin\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\sherin\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\sherin\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "df_aspek = pd.read_csv('C:/KULIAH/SEMESTER 7/skripsi bismillah fix/SHERINA AVIANITA/svm/layanan/skripsi/preprocessing_test_copy.csv', index_col=0)\n",
    "df_tw = pd.read_csv('C:/KULIAH/SEMESTER 7/skripsi bismillah fix/SHERINA AVIANITA/svm/layanan/skripsi/tfidf_test_copy.csv')\n",
    "\n",
    "X = np.array(df_tw.values.tolist())\n",
    "y = np.array(df_aspek['Label'].values.tolist()) \n",
    "\n",
    "\n",
    "acc = []\n",
    "prediksi = []\n",
    "ekspektasi = []\n",
    "\n",
    "classifier = LinearSVC(multi_class='ovr',random_state=0 )\n",
    "n_iterasi = 1000\n",
    "for i in range (n_iterasi):\n",
    "    skf = StratifiedKFold (n_splits=10, random_state=0, shuffle=True)\n",
    "    skf.get_n_splits(X, y)\n",
    "x = 1\n",
    "\n",
    "writer = pd.ExcelWriter('C:/KULIAH/SEMESTER 7/skripsi bismillah fix/SHERINA AVIANITA/svm/layanan/skripsi/prediksi_layanan_copy.xlsx')\n",
    "\n",
    "#partisi data\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    classifier.fit(X_train,y_train) \n",
    "\n",
    "#menyimpan data prediksi\n",
    "    prediction= classifier.predict(X_test)\n",
    "    prediksi.extend(prediction)\n",
    "    excelDF = []\n",
    "    for i, val in enumerate(test_index):\n",
    "        excelDF.append(pd.DataFrame({\n",
    "            \"INDEX\": [val],\n",
    "            \"ULASAN\": [df_aspek['Review'][val]],\n",
    "            \"LABEL_ASLI\": [df_aspek['Label'][val]],\n",
    "            \"LABEL_PREDIKSI\": [prediction[i]]\n",
    "        }))\n",
    "    \n",
    "    excelDF = pd.concat(excelDF)\n",
    "    excelDF.to_excel(writer, sheet_name=\"Fold-\"+str(x))\n",
    "    \n",
    "    # menyimpan data label yang diharapkan\n",
    "    ekspektasi.extend(y_test)\n",
    "    \n",
    "    #menghitung akurasi\n",
    "    score=accuracy_score(y_test,prediction)\n",
    "    acc.append(score)\n",
    "    x += 1\n",
    "    writer.save()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83870968 0.87096774 0.80645161 0.80645161 0.93548387 0.70967742\n",
      " 0.87096774 0.83333333 0.96666667 0.96666667]\n",
      "[[123   8   4]\n",
      " [  9  27   7]\n",
      " [ 13   2 114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.91      0.88       135\n",
      "           0       0.73      0.63      0.68        43\n",
      "           1       0.91      0.88      0.90       129\n",
      "\n",
      "    accuracy                           0.86       307\n",
      "   macro avg       0.83      0.81      0.82       307\n",
      "weighted avg       0.86      0.86      0.86       307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluasi confusion matrix\n",
    "\n",
    "accuracy = np.array(acc)\n",
    "print(accuracy)\n",
    "\n",
    "confusionmatrix = confusion_matrix(ekspektasi,prediksi)\n",
    "print(confusionmatrix)\n",
    "\n",
    "report=metrics.classification_report(ekspektasi,prediksi)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Rata-Rata: 0.8605376344086022\n"
     ]
    }
   ],
   "source": [
    "#evaluasi confusion matrix\n",
    "accuracy = np.array(acc).mean()\n",
    "print('Akurasi Rata-Rata:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Tiap Fold: [0.83870968 0.87096774 0.80645161 0.80645161 0.93548387 0.70967742\n",
      " 0.87096774 0.83333333 0.96666667 0.96666667]\n",
      "Akurasi Rata-Rata: 0.8605376344086022\n",
      "\n",
      " [[123   8   4]\n",
      " [  9  27   7]\n",
      " [ 13   2 114]]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.91      0.88       135\n",
      "           0       0.73      0.63      0.68        43\n",
      "           1       0.91      0.88      0.90       129\n",
      "\n",
      "    accuracy                           0.86       307\n",
      "   macro avg       0.83      0.81      0.82       307\n",
      "weighted avg       0.86      0.86      0.86       307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluasi confusion matrix\n",
    "\n",
    "accuracy = np.array(acc)\n",
    "print('Akurasi Tiap Fold:', accuracy)\n",
    "accuracy = np.array(acc).mean()\n",
    "print('Akurasi Rata-Rata:', accuracy)\n",
    "\n",
    "confusionmatrix = confusion_matrix(ekspektasi,prediksi)\n",
    "print('\\n', confusionmatrix)\n",
    "report=metrics.classification_report(ekspektasi,prediksi)\n",
    "print('\\n', report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kata Teratas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     ribet mesan\n",
       "1                               tidak masuk layan\n",
       "2                                     layan cepat\n",
       "3    lama layan beli nasi sayur akhir aku tinggal\n",
       "4     layan cepat kasir ojek online sendiri kasir\n",
       "Name: text_join, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def join_text_list(texts):\n",
    "    texts = ast.literal_eval(texts)\n",
    "    return ' '.join([text for text in texts])\n",
    "df2[\"text_join\"] = df2[\"final preprocessing\"].apply(join_text_list)\n",
    "\n",
    "df2[\"text_join\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=0.0,\n",
       "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cvector = CountVectorizer(min_df = 0.0, max_df = 1.0, ngram_range=(1,2))\n",
    "cvector.fit(df2.text_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positif</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>layan</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>makan</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempat</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cepat</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layan cepat</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banyak</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baik</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyaman</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enak</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tidak</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagus</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ramai</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mantap</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harga</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semua</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             positif\n",
       "Terms               \n",
       "layan             80\n",
       "makan             45\n",
       "tempat            45\n",
       "cepat             41\n",
       "layan cepat       24\n",
       "banyak            23\n",
       "baik              22\n",
       "nyaman            21\n",
       "enak              21\n",
       "tidak             19\n",
       "bagus             18\n",
       "ramai             18\n",
       "mantap            17\n",
       "harga             16\n",
       "semua             15"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Positif\n",
    "\n",
    "pos = cvector.transform(df2[df2.Label == 1].text_join)\n",
    "\n",
    "pos_words = pos.sum(axis=0)\n",
    "pos_words_freq = [(word, pos_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\n",
    "pos_tf = pd.DataFrame(list(sorted(pos_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','positif'])\n",
    "\n",
    "pos_tf_df = pos_tf.set_index('Terms')\n",
    "pos_tf_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>makan</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tidak</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layan</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kasir</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antre</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lama</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempat</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pesan</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bayar</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kurang</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lebih</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ramai</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jam</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parkir</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datang</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "Terms        \n",
       "makan      46\n",
       "tidak      45\n",
       "layan      42\n",
       "kasir      39\n",
       "antre      31\n",
       "lama       29\n",
       "tempat     26\n",
       "pesan      25\n",
       "bayar      24\n",
       "kurang     23\n",
       "lebih      20\n",
       "ramai      18\n",
       "jam        18\n",
       "parkir     17\n",
       "datang     17"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Negatif\n",
    "\n",
    "neg = cvector.transform(df2[df2.Label == -1].text_join)\n",
    "\n",
    "neg_words = neg.sum(axis=0)\n",
    "neg_words_freq = [(word, neg_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\n",
    "neg_tf = pd.DataFrame(list(sorted(neg_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','count'])\n",
    "\n",
    "neg_tf_df = neg_tf.set_index('Terms')\n",
    "neg_tf_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terms</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>makan</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bayar</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kasir</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempat</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pesan</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kartu</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bayar kasir</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duduk</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>menu</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sistem</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count\n",
       "Terms             \n",
       "makan           51\n",
       "bayar           33\n",
       "kasir           30\n",
       "tempat          27\n",
       "pesan           25\n",
       "kartu           14\n",
       "bayar kasir     12\n",
       "duduk           11\n",
       "menu             9\n",
       "sistem           9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Netral\n",
    "\n",
    "net = cvector.transform(df2[df2.Label == 0].text_join)\n",
    "\n",
    "net_words = net.sum(axis=0)\n",
    "net_words_freq = [(word, net_words[0, idx]) for word, idx in cvector.vocabulary_.items()]\n",
    "net_tf = pd.DataFrame(list(sorted(net_words_freq, key = lambda x: x[1], reverse=True)),columns=['Terms','count'])\n",
    "\n",
    "net_tf_df = net_tf.set_index('Terms')\n",
    "net_tf_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
